---
title: "GenAI Adoption in Software Engineering – Plandek 2025 Report"
date: 2025-06-01
layout: summary.njk
tags: [ai, strategy, implementation]
summary: |
  Plandek’s 2025 Intelligence Report examines the rapid uptake of generative AI tools in software engineering, finding widespread yet uneven adoption. While most organisations report individual-level benefits, organisational impact on quality, velocity, and product fit remains limited, with measurement practices still immature.
---

## Source and link
- Authors: Plandek research team
- Venue: Plandek 2025 Intelligence Report
- Link: (https://drive.google.com/file/d/10qiK9jq1yW1aYE1OmM9Fzg9oa61jlYuA/view?usp=drive_link)
  
## What the paper claims
The report argues that generative AI is being adopted at unprecedented speed in software engineering, but its transformative potential will only be realised if organisations professionalise their approach — implementing robust measurement, risk management, and structured integration into delivery processes.

## Methods or approach
A mixed-methods study was conducted in H1 2025, combining a structured online survey of ~15,000 engineers with optional interviews and roundtables. Respondents included CTOs, VPs of Engineering, and senior technical leaders from multiple industries and geographies. Data was segmented by company size, industry, use case complexity, and delivery maturity.

## Key findings
- 88% of organisations have begun using GenAI tools, with 60% adopting in the past 6 months.
- Adoption is inconsistent, often limited to individuals or specific teams, and heavily skewed toward coding tasks.
- A significant “expectation vs reality” gap exists: quality improvements lag far behind expectations, while cost reduction exceeds them.
- 85% have no or rudimentary measurement of impact; most benefits reported are anecdotal.
- 50% expect GenAI to change team structure or hiring within 24 months.

## Limitations and caveats
- Data relies on self-reported usage and perceptions, with limited objective telemetry.
- Organisational impact is difficult to isolate from other process changes.

## Implications for practitioners
- Establish formal measurement frameworks (e.g. SEI tools) to quantify adoption and outcomes.
- Introduce clear policies, risk controls, and security guardrails for AI-assisted development.
- Invest in training, knowledge-sharing, and iterative process redesign to align tools with delivery goals.

## Notable passages quoted
> "An ‘Expectation versus Reality Gap’ with quality, velocity and product-fit not improving as expected and many benefits seen at individual level only." — Key findings section

> "To realise the gains and manage the risks, there is an urgent need to ‘professionalise’ adoption of GenAI tools in software delivery." — Recommendations section
